#!/usr/bin/env python
import argparse
import datetime as dt
import subprocess as sp
import os, shutil, sys
from glob import glob

## get command line arguments
parser = argparse.ArgumentParser(description=(
    "Downloads the ocean initial conditions for the CFSR"))
parser.add_argument('--start', metavar='date', required=True, help=(
    'start date of data to get, format is "YYYYMMDD"'))
parser.add_argument('--end', metavar="date",help=(
    'end date of the data to get, format is "YYMMDD", if no date is '
    'given, only the start date is downloaded'))
parser.add_argument('--daily', action='store_true',default=False,help=(
    'if set, only the 00z data is kept (default False)'))
args=parser.parse_args()
if not args.end:
    args.end=args.start


## create temporary work directory
tmpdir=os.getenv('TMP_DIR_LOCAL')+'/get_cfsr_ocnIC'
if os.path.exists(tmpdir):
   shutil.rmtree(tmpdir)
outdir=os.getenv("CFSR_DIR")
    
## start the loop    
cdate = dt.datetime.strptime(args.start,'%Y%m%d')
edate = dt.datetime.strptime(args.end,'%Y%m%d')
data_url = "http://nomads.ncdc.noaa.gov/modeldata/cmd_HIC"  #T126
while cdate <= edate:
    os.makedirs(tmpdir)
    print cdate

    ## download the file
    tarfile = cdate.strftime("/%Y/%Y%m/%Y%m%d/cfs_reanalysis_HIC_%Y%m%d00.tar.gz")
    sp.call('wget '+data_url+tarfile,shell=True,cwd=tmpdir)

    ## extract the required files
    print tmpdir
    sp.call('tar -xaf '+os.path.basename(tarfile)+' ocnanl.gdas.*', shell=True, cwd=tmpdir)

    
    ## move to output directory
    outpfx = outdir+'/'+cdate.strftime('ocn_05/%Y/%Y%m/%Y%m%d/')
    if not os.path.exists(os.path.dirname(outpfx)):
        os.makedirs(os.path.dirname(outpfx))
    for h in ['00','06','12','18']:
        files = glob(tmpdir+'/ocnanl.gdas.*')
        for f in files:
            shutil.move(f, outpfx+'/'+os.path.basename(f))
    shutil.rmtree(tmpdir)
    
    cdate += dt.timedelta(days=1)
