#!/usr/bin/env python
############################################################
##
## TODO, insert description
##
############################################################

## load built-int python modules
import argparse
import os, sys, shutil
import subprocess as sp
from glob import glob
import datetime as dt
import hashlib

## load our own modules
import common
sys.path.insert(1,os.getenv("CFS_LETKF_ROOT")+'/common/python')
import obsio
obsio.reclen=10

## setup the logging system
log = common.setupLog()

############################################################
## get the command line / env arguments

parser = argparse.ArgumentParser(description=(
    "TODO, insert description"))

## required arguments
parser.add_argument('path', metavar="PATH", help=(
    "Path to the directory storing the experiment."))
parser.add_argument('date', metavar="DATE", help=(
    "Date that the forecasts were started from, in YYYYMMDDHH format."
    " E.g. for an analysis at 2010010106, 2010010100 would be passed in here."))

## optional arguments
parser.add_argument('--ares', type=int, choices=common.aresList, default=62, help=(
    "Horizontal resolution of atmosphere, (Default: 62)"))
parser.add_argument('--ores', choices=['05','1'], default='05', help=(
    "Horizontal resolution of the ocean, either 1/2 (05) or 1 (1x1) degree. (Default: 05)"))
parser.add_argument("--aobs", action="store_true", default=False, help=(""))
parser.add_argument("--oobs", action="store_true", default=False, help=(""))
parser.add_argument("--async", type=int, default=0, help=(
    "number of hours prior to also use for atm obs"))
parser.add_argument("--mem", type=int)

parser.add_argument('--obsavg', action='store_true')
parser.add_argument('--calcmin', action="store_true")

## parse the arguments
args = parser.parse_args()
args.path = os.path.abspath(args.path)
args.date = dt.datetime.strptime(args.date, "%Y%m%d%H")
args.wrkdir = os.path.abspath(os.getenv("TMP_DIR_SHARED")+ "/cfs-letkf-ocn_" + \
                              hashlib.md5(args.path).hexdigest()[0:6])
if args.mem is None:
    args.mem = common.getEnsMem(args.path)

mems = range(1,args.mem+1)
dateShort = args.date.strftime("%Y%m%d%H")
ndate = args.date+dt.timedelta(hours=6)
ndateShort = ndate.strftime("%Y%m%d%H")



############################################################
## print some configuration information
log.info("MOM-LETKF, originally developed by Steve Penny.")
log.info("Modified for strongly coupled CFS-LEKTF by")
log.info("Travis Sluka, University of Maryland, 2016")
log.info("")
log.info("Configuration: \n"+str(args)+"\n")



############################################################
## setup the working directory
if os.path.exists(args.wrkdir):
    log.warn("Removing existing working directory")
    shutil.rmtree(args.wrkdir)
os.makedirs(args.wrkdir)
os.symlink(os.getenv("FIX_DIR_OM")+"/grid_spec_{}.nc.T{}".format(
    "1x1" if args.ores == "1" else args.ores, args.ares),
           args.wrkdir+'/grid_spec.nc')
shutil.copy(args.path+"/cfg/letkf.nml", args.wrkdir+'/input.nml')


## copy background and make analysis placeholder files
log.info('copying background and making analysis placeholder files')
jobs=[]
for m in mems:
    for f in ['temp_salt','velocity','sbc']:
        ## ocean background
        os.symlink(args.path+'/gues/{:03d}/{}_F06.ocean_{}.res.nc'.format(m,dateShort,f),
                   args.wrkdir+'/gs01{:03d}.ocean_{}.res.nc'.format(m,f))
        ## ocean analysis, copy these files since the LETKF
        ## requires that the netcdf file already exist
        cmd = "cp gs01{0:03d}.ocean_{1}.res.nc anal{0:03d}.ocean_{1}.res.nc".format(m,f)
        jobs.append(sp.Popen(cmd,shell=True, cwd=args.wrkdir))
for j in jobs:
    j.wait()
    if (j.returncode >0 ):
        log.error("error copying background files")
        sys.exit(1)

        
## create a combined obsdep file
log.info('creating combined obsdep file')
if args.obsavg and ndate.hour == 0 and args.oobs:
    log.info(' using averaging of past 24 hours of ocean output')
elif not args.obsavg and ndate.hour == 12 and args.oobs:
    log.info(' using instantaneous ocean output at 12 hr')    
    

for m in mems:
    obsfile = args.wrkdir+'/obs01{:03d}.dat'.format(m)
    sp.check_call('touch '+obsfile, shell=True)

    ## atmospheric obserbations
    atmobsfile = args.wrkdir+'/atm{:03d}.dat'.format(m)    
    if (args.aobs):
        d = ndate
        while (d >= ndate-dt.timedelta(hours=args.async)):
            if m == 1:
                log.info("searching for atm obs for "+str(d))
            afile=args.path+'/obsop/{}_atm{:03d}.dat'.format(d.strftime("%Y%m%d%H"),m)
            if os.path.exists(afile):
                if m == 1:
                    log.info("Found.")
                sp.check_call('cat {} >> {}'.format(afile, atmobsfile), shell=True)                    
            else:
                if m == 1:
                    log.warn("NOT found.")
            d = d-dt.timedelta(hours=6)
    sp.check_call('touch '+atmobsfile, shell=True)
            

    ## ocean observations
    ocnobsfile = args.wrkdir+'/ocn{:03d}.dat'.format(m)
    if args.obsavg and ndate.hour == 0 and args.oobs:
        ## determine the mean/min of observations over the past 24 hours
        odate = ndate-dt.timedelta(hours=18)
        obs=None
        cnt = 0
        while odate <= ndate:            
            odateShort = odate.strftime("%Y%m%d%H")        
            ofile=args.path+'/obsop/{}_ocn{:03d}.dat'.format(odateShort,m)
            if (os.path.exists(ofile)):
                tobs = obsio.read(ofile)
                cnt += 1                
                if obs is None:
                    obs = tobs
                else:
                    for i in range(len(obs)):
                        o = obs[i]
                        if args.calcmin:
                            val = min(o[8], tobs[i][8])
                        else:
                            val = o[8]+ tobs[i][8]
                        obs[i] = (o[0], o[1], o[2], o[3], o[4], o[5], o[6], o[7],
                                  val, min(o[9], tobs[i][9]))
            odate += dt.timedelta(hours=6)
        if obs:
            if not args.calcmin:
                for i in range(len(obs)):
                    o = obs[i]
                    obs[i] = (o[0], o[1], o[2], o[3], o[4], o[5], o[6], o[7],
                              o[8]/cnt, o[9])
            obsio.write(obs, ocnobsfile)
            
    elif not args.obsavg and ndate.hour == 12 and args.oobs:
        sp.check_call('ln -s {} {}'.format(
            args.path+'/obsop/{}_ocn{:03d}.dat'.format(ndateShort,m)
            , ocnobsfile), shell=True)
            
    sp.check_call('touch {}'.format(ocnobsfile), shell=True)            

    ## create combined file
    sp.check_call('mv {1} {0}; cat {2} >> {0}'.format(
        obsfile, atmobsfile, ocnobsfile), shell=True)


## determine observation space background mean
if ( (ndate.hour == 0 and args.obsavg) or (ndate.hour == 12 and not args.obsavg) )and args.oobs:    
    log.info("calculating ocn background mean in observation space")
    odate = ndate-dt.timedelta(hours=24)
    obs= None
    for m in mems:
        ocnobsfile = args.wrkdir+'/ocn{:03d}.dat'.format(m)
        tobs = obsio.read(ocnobsfile)
        if obs is None:
            obs = tobs
        else:
            for i in range(len(obs)):
                o = obs[i]
                val = o[8]+ tobs[i][8]
                obs[i] = (o[0], o[1], o[2], o[3], o[4], o[5], o[6], o[7],
                      val, min(o[9], tobs[i][9]))
    for i in range(len(obs)):
        o = obs[i]
        obs[i] = (o[0], o[1], o[2], o[3], o[4], o[5], o[6], o[7],
              o[8]/len(mems), o[9])
    if args.obsavg:
        fname=args.path+'/gues/omb/'+odate.strftime("%Y/%Y%m/%Y%m%d/%Y%m%d_ocn.dat")
    else:
        fname=args.path+'/gues/omb/'+ndate.strftime("%Y/%Y%m/%Y%m%d/%Y%m%d_ocn.dat")

    log.info("writing to "+fname)
    fname_dir = os.path.dirname(fname)
    if not os.path.exists(fname_dir):
        os.makedirs(fname_dir)
    obsio.write(obs, fname)    
    
    

## adaptive inflation
log.warn("Adaptive inflation file is not being copied")



############################################################
## LETKF
log.info("Running MOM-LETKF")
ret = sp.call("mpirun -n $NPROC_LETKF_O $CFS_LETKF_ROOT/letkf-mom/letkf/letkf $> letkf.log",
              shell=True, cwd=args.wrkdir)
with open(args.wrkdir+"/NOUT-0000",'r') as f:
    log.info(f.read())



############################################################
##
log.info("moving files...")
jobs=[]
for m in mems:
    for f in ['temp_salt','velocity','sbc']:
        cmd = "mv anal{0:03d}.ocean_{1}.res.nc {2}/anal/{0:03d}/{3}.ocean_{1}.res.nc".format(
            m, f, args.path, ndateShort)
        jobs.append(sp.Popen(cmd,shell=True, cwd=args.wrkdir))
for j in jobs:
    j.wait()
    if (j.returncode >0 ):
        log.error("error copying output files")
        sys.exit(1)
files = [
    ('gues_me.grd', '/gues/mean/{}_ocn.grd'),
    ('gues_sp.grd', '/gues/sprd/{}_ocn.grd'),
    ('anal_me.grd', '/anal/mean/{}_ocn.grd'),
    ('anal_sp.grd', '/anal/sprd/{}_ocn.grd')]
if (os.path.exists(args.wrkdir+'/infl_out.grd')):
    files.append( ('infl_out.grd', '/infl_mul/{}_ocn.grd') )
jobs = []
dateStr = ndate.strftime('%Y/%Y%m/%Y%m%d/%Y%m%d%H/%Y%m%d%H')
for f in files:
    dst = args.path+f[1].format(dateStr)
    dstDir = os.path.dirname(dst)
    if (not os.path.exists(dstDir)): os.makedirs(dstDir)
    cmd = "mv {} {}".format( f[0], dst)
    jobs.append(sp.Popen(cmd,shell=True, cwd=args.wrkdir))
for j in jobs:
    j.wait()
    if (j.returncode > 0):
        log.error("Problem copying files.")
        sys.exit(1)
    
## Create links for the restart files that were not changed
for m in mems:
    files = ['ocean_{}.res.nc'.format(x) for x in [
        'density', 'frazil','freesurf','neutral','velocity_advection']]
    files += ['fluxes_restart', 'ice_model.res.nc']
    
    for f in files:
        try:
            os.symlink(args.path+'/gues/{:03d}/{}_F06.{}'.format(m, dateShort, f),
                       args.path+'/anal/{:03d}/{}.{}'.format(m, ndateShort, f))
        except:
            log.error("Unable to link restart file: {:03d} / {}".format(m,f))
                      
        
############################################################
log.info("Done!")
shutil.rmtree(args.wrkdir)
