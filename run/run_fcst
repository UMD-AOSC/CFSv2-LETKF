#!/usr/bin/env python
############################################################
##
## Runs a single x hour forecast for the CFS model
##
############################################################

## load the built-in python modules
import argparse
import os, shutil, sys
import subprocess as sp
import datetime as dt
from glob import glob

## load our own modules
import common

## setup the logging system
log = common.setupLog()


############################################################
## get the command line / env arguments
parser = argparse.ArgumentParser(description=(
    "CFSv2-LETKF forecast. Runs a single x hour forecast for a "
    "a single ensemble member."))

## required arguments
parser.add_argument("indir", metavar="IN_DIR", help=(
    "Input directory containing the initial conditions of the model"))
parser.add_argument("outdir", metavar="OUT_DIR", help=(
    "Output directory to place the results"))
parser.add_argument("date", metavar="DATE", help=(
    "Date of the initial conditions of the forecast, in YYYYMMDDHH format"))
parser.add_argument("--nemonml", required=True)

## optional arguments
parser.add_argument("--len", metavar="LEN", type=int, default=9, help=(
    "Forecast length, in hours. (Default: 9)"))
parser.add_argument("--ares", default=62, type=int, help=(
    "TODO, finish the description for this"))
parser.add_argument("--ores", default="05", choices=["05","1"], help=(
    "Ocean resolution, either \"05\" for half degree, or \"1\" for 1 degree"))
parser.add_argument("--wrkdir", metavar="DIR",
    default=os.getenv("TMP_DIR_SHARED")+'/cfs_fcst', help=(
    "Temporary directory in which to do the work. (Default: $TMP_DIR_SHARED/cfs_fcst)"))
parser.add_argument("--copy", action="store_true", help=(
    "By default, the executables and files are linked to the working "
    "directory, this will instead copy the files"))
parser.add_argument("--period", type=int, default=1, help=(
    "Period of atmosphere output, in hours. (Default: 1)"))
parser.add_argument("--oisst", action="store_true", default=False, help=(
    "If true, the observed daily OISSTv2 is used to relax the SST"))

## parse the arguments
args = parser.parse_args()
args.date = dt.datetime.strptime(args.date, "%Y%m%d%H")
args.wrkdir = os.path.abspath(args.wrkdir)
args.ares_x,args.ares_y = common.getAtmRes(args.ares)
#args.ores = '05' ## TODO, make this configurable (05 or 1x1)
if args.ores == '1':
    args.ores = '1x1'

if args.oisst:
    args.sfcRstr = os.getenv('CFS_LETKF_ROOT')+'/DATA/oisst/'+args.date.strftime('%Y/%Y%m/%Y%m%d.nc')
else:
    args.sfcRstr = os.getenv('FIX_DIR_OM')+'/temp_sfc_restore_{}.nc'.format(args.ores)
args.sfcRstr=os.path.abspath(args.sfcRstr)
                    
args.indir=os.path.abspath(args.indir)
args.outdir=os.path.abspath(args.outdir)
cl = 'cp' if args.copy else 'ln -s'
dateShort = args.date.strftime("%Y%m%d%H")
ndate = args.date + dt.timedelta(hours=6)


############################################################
## print some basic information
log.info("CFSv2 Forecast")
log.info(" running on: "+os.uname()[1])
log.info(" SLURM nodes: "+os.getenv("SLURM_NODELIST"))
log.info("Configuration:\n"+str(args))


############################################################
## set things up to run the forecast
############################################################

##############################
log.info("Creating working directory...")
if os.path.exists(args.wrkdir):
    shutil.rmtree(args.wrkdir)
    log.warn("The old working directory {} was deleted".format(args.wrkdir))
#for d in [args.wrkdir, args.wrkdir+'/RESTART', args.wrkdir+'/IRESTART',
for d in [args.wrkdir+'/INPUT', args.wrkdir+'/fix_am']:
    if not os.path.exists(d):
        os.makedirs(d)

#TODO, IRESTART folder probably needs to be put on TMP_DIR_SHARED if
# more than 1 node is used for the ocean.
sp.check_call('mkdir -p $TMP_DIR_LOCAL/irestart', shell=True)
sp.check_call('ln -s $TMP_DIR_LOCAL/irestart IRESTART', shell=True, cwd=args.wrkdir)
# TODO, there has to be someway to disable RESTART writing it in the MOM input.nml file
sp.check_call('mkdir -p $TMP_DIR_LOCAL/restart', shell=True)
sp.check_call('ln -s $TMP_DIR_LOCAL/restart RESTART', shell=True, cwd=args.wrkdir)
        
##############################        
log.info("copying executables...")
sp.call(cl+" $CFS_LETKF_ROOT/cfs/bin/* .", shell=True, cwd=args.wrkdir)


##############################
## Check to see if the coupler restart file exists
## copy restart file if it exists
flx_file = glob("{}/{}.fluxes_restart".format(args.indir,dateShort))
cpl_restart = len(flx_file) == 1
if cpl_restart:
    sp.call(cl+" {} {}/fluxes_for_OM".format(flx_file[0], args.wrkdir), shell=True)
else:
    log.warn("No coupler flux restart file was found, this is normal for the first run only")
    sp.call(cl+" $FIX_DIR_OM/fluxes_init_OM_t{} {}/fluxes_init_OM".format(
        args.ares, args.wrkdir), shell=True)    


##############################
log.info("Creating OCN config files...")
env = os.environ
env['restart']    = "T" if cpl_restart else "F"
env['START_DATE'] = dateShort
env["FCST_LEN"]   = str(args.len)
env["CPL_PERIOD"] = str(300) ##TODO, make this configurable ?
env["OUT_PERIOD"] = str(args.period)
env["AM_RES"]     = str(args.ares)
env["AM_RES_X"]   = str(args.ares_x)
env["AM_RES_Y"]   = str(args.ares_y)
sp.call("source $CFS_LETKF_ROOT/run/config_files/cpl_nml > cpl_nml",
        shell=True, cwd=args.wrkdir)
sp.call("source {} > input.nml".format(args.nemonml),
        shell=True, cwd=args.wrkdir)
sp.call(cl+" $CFS_LETKF_ROOT/run/config_files/d???_table .",
        shell=True, cwd=args.wrkdir)


##############################
log.info("Copying OCN fix files...")
momFiles=[
    ("$FIX_DIR_OM/MOM4LND05GFSOCNt{ares}.msk",     "MOM4LND_GFSOCN"),
    ("$FIX_DIR_OM/grid_spec_{ores}.nc.T{ares}",    "INPUT/grid_spec.nc"),
    ("$FIX_DIR_OM/chl_{ores}.nc",                  "INPUT/chl.nc"),
    ("$FIX_DIR_OM/r2ts_clim.nc",                   "INPUT/"),
    ("$FIX_DIR_OM/sst_ice_clim.nc",                "INPUT/"),
    ("$FIX_DIR_OM/runoff_{ores}.nc",               "INPUT/runoff.nc"),   
    (args.sfcRstr,                                 "INPUT/temp_sfc_restore.nc"),
    ("$FIX_DIR_OM/salt_sfc_restore_05.nc",         "INPUT/salt_sfc_restore.nc"),
    ("$FIX_DIR_OM/ohf_sice.nc",                    "INPUT/")  ]
for x in momFiles:
    arg1 = x[0].format(ores=args.ores,ares=str(args.ares))
    sp.call(cl+" "+arg1+" "+x[1],
            shell=True, cwd=args.wrkdir)

    
##############################
log.info("Copying OCN initial conditions...")
files = ['ocean_'+x for x in [
    'density','sbc','velocity','velocity_advection',
    'freesurf','temp_salt','frazil','neutral'] ]
files += ['ice_model',]
for f in files:
    sp.call(cl+' {0}/{1}.{2}.res.nc {2}.res.nc'.format(
        args.indir, dateShort, f),
            shell=True, cwd=args.wrkdir+'/INPUT')

    
##############################
log.info("Copying ATM initial conditions...")
for f in ['sfc','sig']:
    sp.call(cl+' '+args.indir+'/'+dateShort+'.'+f+' '+f+'_ini',
            shell=True, cwd=args.wrkdir)

    
##############################
log.info("Creating ATM namelist")
sp.call("source $CFS_LETKF_ROOT/run/config_files/gfs_namelist "
        "> gfs_namelist",
        shell=True, cwd=args.wrkdir)
sp.call("source $CFS_LETKF_ROOT/run/config_files/gfs_namelist.rc "
        "> gfs_namelist.rc",
        shell=True, cwd=args.wrkdir)


##############################
log.info("Copyhing ATM fix files...")
files = [
    ("climaeropac_global.txt", "aerosol.dat"),
    ("co2con.l64.f77",     "fort.15"),
    ("mtnvar.t{ares}.f77", "fort.24"),
    ("tbthe.f77",          "fort.27"),
    ("o3prdlos.f77",       "fort.28"),
    ("cldtune.f77",        "fort.43"),
    ("o3clim.txt",         "fort.48"),
    ("orography.t{ares}.grb", "orography"),
    ("orography_uf.t{ares}.{ares_x}.{ares_y}.grb", "orography_uf"),
    ("sfc_emissivity_idx.txt", "sfc_emissivity_idx.txt"),
    ("solarconstantdata.txt", "solarconstantdata.txt")]
for y in range(1956,2009+1):
    files += [("co2historicaldata_{}.txt".format(y),
               "co2historicaldata_{}.txt".format(y))]

for f in files:
    cmd = f[0].format(ares=args.ares, ares_x=args.ares_x, ares_y=args.ares_y)
    sp.call(cl+" $FIX_DIR_AM/global_{} {}".format(cmd,f[1]),
            shell=True, cwd=args.wrkdir)
files=[
    'global_glacier.2x2.grb',
    'global_maxice.2x2.grb',
    'cfs_oi2sst1x1monclim19822001.grb',
    'global_snoclim.1.875.grb',
    'global_zorclim.1x1.grb',
    'global_albedo4.1x1.grb',
    'cfs_ice1x1monclim19822001.grb',
    'global_tg3clim.2.6x1.5.grb',
    'global_vegfrac.0.144.decpercent.grb',
    'seaice_newland.grb',
    'global_vegtype.1x1.grb',
    'global_vegfrac.1x1.grb',
    'global_soiltype.1x1.grb',
    'global_shdmin.0.144x0.144.grb',
    'global_shdmax.0.144x0.144.grb',
    'global_slope.1x1.grb',
    'global_snoalb.1x1.grb',
    'global_soilmcpc.1x1.grb',
]
for f in files:
    sp.call(cl+" $FIX_DIR_AM/{} fix_am/".format(f),
            shell=True, cwd=args.wrkdir)

    
############################################################    
## Run the model
log.info("Running the CFS model...")
env['OMP_NUM_THREADS']=str(1)
stime= dt.datetime.now()
cmd = ('mpirun -n 1 cfs_mlc_coupler : '
       '-n $NPROC_OM cfs_ocean_mom4ice : '
       '-n $NPROC_AM global_fcst &> cfs.log')
if (sp.call(cmd, shell=True, cwd=args.wrkdir, env=env) > 0):
    log.error("problem running CFS")
    log.info("CFS log file: ")
    f = open(args.wrkdir+'/cfs.log','r')
    log.info(f.read())    
    sys.exit(1)
etime = dt.datetime.now()
log.info("CFS run finished in {} seconds.".format((etime-stime).seconds))

## TODO, check to make sure the required output files have indeed been created



############################################################
## move the output

## ensure output directory exists
if not os.path.exists(args.outdir):
    os.makedirs(args.outdir)

    
## copy ocean files
log.info("Copying OCN output...")
jobs=[]
files = glob(args.wrkdir+"/IRESTART/*.res.nc")
for f in files:
    fdate = dt.datetime.strptime(f.split('/')[-1][0:10],"%Y%m%d%H")
    fhr = int((fdate-args.date).total_seconds()/3600)
    cmd = 'mv {} {}/{}_F{:02d}.{}'.format(
        f, args.outdir, dateShort, fhr, os.path.basename(f)[10:])
    jobs.append( sp.Popen(cmd, shell=True) )
[j.wait() for j in jobs]
for j in jobs:
    if j.returncode >0:
        sys.exit(1)

## copy atm files
log.info("Copying ATM output...")
jobs=[]
for i in range(1,args.len/args.period+1):
    f = i*args.period
    cmd = 'mv {0}/SIG.F{1:02d} {2}/{3}_F{1:02d}.sig'.format(
        args.wrkdir, f, args.outdir, dateShort)
    jobs.append( sp.Popen(cmd, shell=True) )
    cmd = 'mv {0}/SFC.F{1:02d} {2}/{3}_F{1:02d}.sfc'.format(
        args.wrkdir, f, args.outdir, dateShort)
    jobs.append( sp.Popen(cmd, shell=True) )
[j.wait() for j in jobs]
for j in jobs:
    if j.returncode >0:
        sys.exit(1)

## copy the flux restart file
log.info("Copying flux restart file for coupler")
files = glob("{}/fluxes_for_OM_*".format(args.wrkdir))
if len(files) == 0:
    log.critical("Cannot find the flux restart file")
    sys.exit(1)
for f in files:
    fh = int(f.split('_')[-1])/12
    shutil.copy(f, "{}/{}_F{:02d}.fluxes_restart".format(
        args.outdir, dateShort, fh))
    

## all done
log.info("Finished!!")

## print out the cfs log file at the end of this log
log.info("CFS log file: ")
f = open(args.wrkdir+'/cfs.log','r')
log.info(f.read())

## clear out the temporary directory
shutil.rmtree(args.wrkdir)
