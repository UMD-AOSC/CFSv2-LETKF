#!/usr/bin/env python
#SBATCH -n 20
################################################################################

## load built-in modules
import sys
import argparse
import os, shutil
import subprocess as sp
from glob import glob
import datetime as dt
import multiprocessing as mp

## load 3rd party modules
sys.path.insert(1,'.')
import common

## setup the logging system
log = common.setupLog()
log.info("MOM-LETKF, originally developed by Steve Penny")
log.info("")


## directory locations
tmpDir   = os.getenv("TMP_DIR_LOCAL")+'/cfs/mom-letkf'
obsDir   = os.getenv("CFS_LETKF_ROOT")+'/DATA/obs/PROFS_gerr_TS_deep'
letkfDir = os.getenv("CFS_LETKF_ROOT")+'/letkf-mom/mom4'
fixDir = os.getenv("FIX_DIR_OM")


## get the command line arguments
parser = argparse.ArgumentParser(
    formatter_class = argparse.ArgumentDefaultsHelpFormatter,
    description=(
        "CFS-LETKF data assimilation step for the MOM"))

## required variables
g = parser.add_argument_group(title="required parameters")
g.add_argument('--date', metavar='date', required=True,
    help="date to perform the analysis for, in format of YYYYMMDDHH")
g.add_argument('--path', metavar='path', required=True,
    help="path to the directory storing the experiment")

## optional variables
g = parser.add_argument_group(title="optional parameters")
g. add_argument('--mem', metavar='members', type=int,
    help=("number of ensemble members. BY default the script "
          "will automatically determine the number of ensemble "
          "members based on the directory structure in the path given"))
g.add_argument('--ares', type=int, choices=[62,126,190,382,574,1148], default=62, help=(
    "horizontal triangular truncation resolution of the atmosphere"))
g.add_argument('--ores', choices=['05','1x1'], default='05', help=(
    "hoizontal resolution of the ocean, either 1/2 (05) or 1 (1x1) degree"))

## parse the variables
args = parser.parse_args()
args.path = os.path.abspath(args.path)
cdate = dt.datetime.strptime(args.date, "%Y%m%d%H")
pdate = cdate - dt.timedelta(hours=6)
cdateShort = cdate.strftime("%Y%m%d%H")  ## current date (the date that was passed in as an arg)
pdateShort = pdate.strftime("%Y%m%d%H")  ## previous date (when the forecast was run from)

## other stuff
log.info(str(args))

## determine the number of ensembe members we are using
if args.mem is None:
    args.mem = common.getEnsMem(args.path)
    log.info("Using {0} ensemble members".format(args.mem))

log.info("")


################################################################################
################################################################################
## do the useful stuff...

mems = ['{0:03d}'.format(m+1) for m in range(args.mem)]

## setup local temporary directory
log.info('Setting up work directory...')
if os.path.exists(tmpDir):
    shutil.rmtree(tmpDir)
os.makedirs(tmpDir)
for m in mems:
    os.makedirs(tmpDir+'/'+m)
for f in ['letkf/letkf','obs/obsop']:
    shutil.copy(letkfDir+'/'+f,tmpDir+'/')
shutil.copy(fixDir+'/grid_spec_{}.nc.T{}'.format(args.ores,args.ares),
            tmpDir+'/grid_spec.nc')
shutil.copy(os.getenv("CFS_LETKF_ROOT")+'/run/letkf_mom.nml',
            tmpDir+'/input.nml')

            
## copy the required shared files into the temporary directories
log.info('Copying MOM forecasts...')
for mem in mems:         
    filebase = args.path+'/gues/{}/{}_{}.'.format(
        mem, pdateShort,'F06')
    for f in ['temp_salt','velocity','sbc']:
        ## link to the ocean forecast ensemble (gues)
        os.symlink(filebase+'ocean_{}.res.nc'.format(f),
                   tmpDir+'/gs01{}.ocean_{}.res.nc'.format(mem,f))
        ## copy those files to the analysis files (since writing
        ## the analysis requires the netcdf file to already exist)
        shutil.copy(filebase+'ocean_{}.res.nc'.format(f),
                    tmpDir+'/anal{}.ocean_{}.res.nc'.format(mem,f))


## process the observations
##  right now we only have daily-binned ocean obs, so process these once a day for now
log.info("copying observations...")
useObs = cdate.hour == 12
if useObs:
    ## copy the observations
    log.info('Copying daily binned T&S observations for 12Z')
    obsFile = obsDir+cdate.strftime('/%Y/%Y%m%d.dat')
    shutil.copy(
        obsFile,
        tmpDir+'/obsin.dat')

    ## run the observation operators
    def func(mem):
        sp.call('obsop -obsin obsin.dat -gues gs01{0} -obsout obs01{0}.dat'.format(mem),
                shell=True, cwd=tmpDir)
    mp.Pool().map(func,mems)
        
else:
    log.warn('There are no ocean observations to use')


## copy the adaptive inflation file
inflFile = args.path+'/infl_mul/'+pdate.strftime('%Y/%Y%m/%Y%m%d/%Y%m%d%H/%Y%m%d%H_ocn.grd')
if os.path.exists(inflFile):
    log.info("Copying inflation file...")
    shutil.copy(inflFile, tmpDir+'/infl_mul.grd')
else:
    log.warn("No previous inflation file was found")
    

## run the LETKF
log.info("Running MOM-LETKF...")
ret=sp.call('mpirun letkf', shell=True, cwd=tmpDir)
if ret != 0:
    sys.exit(1)


## move the analysis ensemble members to their final location
log.info("copying ensemble members to destination directory...")
def cp_func(mem):
    for f in ['temp_salt','velocity','sbc']:
        shutil.copy(tmpDir+'/anal{}.ocean_{}.res.nc'.format(mem,f),
            args.path+'/anal/{}/{}.ocean_{}.res.nc'.format(mem,cdateShort,f))
mp.Pool().map(cp_func,mems)


## copy the mean and spread files to their final locations
log.info("copying mean/sprd files to destination directory...")
files=[
    ('gues_me.grd','/gues/mean/{}_ocn.grd'),
    ('gues_sp.grd','/gues/sprd/{}_ocn.grd'),
    ('anal_me.grd','/anal/mean/{}_ocn.grd'),
    ('anal_sp.grd','/anal/sprd/{}_ocn.grd'),
    ('infl_out.grd','/infl_mul/{}_ocn.grd'),]
def cp_func(f):
    dateStr=cdate.strftime('%Y/%Y%m/%Y%m%d/%Y%m%d%H/%Y%m%d%H')
    dst = args.path+f[1].format(dateStr)
    ## make directory
    try:
        os.makedirs(os.path.dirname(dst))
    except:
        pass
    ## copy file
    try:
        shutil.copy(tmpDir+'/'+f[0], dst)
    except:
        if f[0] == 'infl_out.grd':
            log.warn("no inflation file output to copy")
            prevFile = args.path+f[1].format(pdate.strftime('%Y/%Y%m/%Y%m%d/%Y%m%d%H/%Y%m%d%H'))
            if os.path.exists(prevFile):
                log.warn("Copying the previous infl_mul file")
                shutil.copy(prevFile, dst)
            else:
                log.warn("There are no previous inflation files to use either.")
        else:
            log.critical("File {} cannot be copied".format(f[0]))
            sys.exit(1)
        
mp.Pool().map(cp_func,files)


## creat links for the restart files that were not changes
for m in mems:
    files = ['ocean_{}.res.nc'.format(x) for x in [
        'density', 'frazil','freesurf','neutral','velocity_advection']]
    files.append('ice_model.res.nc')
    for f in files:
        try:
            os.symlink(args.path+'/gues/{}/{}_F06.{}'.format(m,pdateShort,f),
                       args.path+'/anal/{}/{}.{}'.format(m,cdateShort,f))
        except:
            pass
    

##TODO move the infl_mul file

##TODO move log viles
f = open(tmpDir+'/NOUT-0000','r')
log.info("\n\nContents of LETKF output file...\n\n")
log.info(f.read())
f.close()


log.info("Finished!")
